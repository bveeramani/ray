{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to train an image classifier using TensorFlow and the [Ray AI Runtime](https://docs.ray.io/en/latest/ray-air/getting-started.html).\n",
    "\n",
    "You should be familiar with TensorFlow before starting this tutorial. If you need a refresher, read TensorFlow's [Convolutional Neural Network](https://www.tensorflow.org/tutorials/images/cnn) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install the [Ray AI Runtime](https://docs.ray.io/en/latest/ray-air/getting-started.html). You'll need Ray 1.13 later to run this example.\n",
    "\n",
    "```\n",
    "pip instsall 'ray[data,tune]'\n",
    "```\n",
    "\n",
    "* Install `tensorflow` and `tensorflow-datasets`\n",
    "\n",
    "```\n",
    "pip install tensorflow tensorflow-datasets\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and normalize CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.data.datasource import SimpleTensorFlowDatasource\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_dataset_factory():\n",
    "    return tfds.load(\"cifar10\", split=[\"train\"], as_supervised=True)[0]\n",
    "\n",
    "def test_dataset_factory():\n",
    "    return tfds.load(\"cifar10\", split=[\"test\"], as_supervised=True)[0]\n",
    "\n",
    "train_dataset = ray.data.read_datasource(  \n",
    "    SimpleTensorFlowDatasource(), dataset_factory=train_dataset_factory\n",
    ")\n",
    "test_dataset = ray.data.read_datasource(SimpleTensorFlowDatasource(), dataset_factory=test_dataset_factory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(batch):\n",
    "    return [(tf.cast(image, tf.float32) / 255.0, label) for image, label in batch]\n",
    "\n",
    "# train_dataset = train_dataset.map_batches(normalize_images)\n",
    "test_dataset = test_dataset.map_batches(normalize_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def convert_batch_to_pandas(batch):\n",
    "    images = [image for image, _ in batch]\n",
    "    labels = [label for _, label in batch]\n",
    "\n",
    "    df = pd.DataFrame({\"image\": images, \"label\": labels})\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "# train_dataset = train_dataset.map_batches(convert_batch_to_pandas)\n",
    "test_dataset = test_dataset.map_batches(convert_batch_to_pandas)\n",
    "\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train\n",
    "from ray.train.tensorflow import prepare_dataset_shard\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    dataset_shard = train.get_dataset_shard(\"train\")\n",
    "    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = build_model()\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "    \n",
    "    for epoch in range(2):\n",
    "        tf_dataset = prepare_dataset_shard(\n",
    "            dataset_shard.to_tf(\n",
    "                feature_columns=[\"image\"],\n",
    "                label_column=\"label\",\n",
    "                output_signature=(\n",
    "                    tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(None, 1), dtype=tf.uint8),\n",
    "                ),\n",
    "                batch_size=config[\"batch_size\"],\n",
    "                unsqueeze_label_tensor=True,\n",
    "            )\n",
    "        )\n",
    "        model.fit(tf_dataset)\n",
    "        train.save_checkpoint(epoch=epoch, model_weights=model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.ml.train.integrations.tensorflow import TensorflowTrainer\n",
    "\n",
    "trainer = TensorflowTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"batch_size\": 2},\n",
    "    datasets={\"train\": test_dataset},\n",
    "    scaling_config={\"num_workers\": 2}\n",
    ")\n",
    "result = trainer.fit()\n",
    "latest_checkpoint = result.checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63e5f6eec01b85d783aa3a898bfbc5e143aba32dbede6a46dbb3b17d5dbd2e6a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
