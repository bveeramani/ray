{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ebe0b1",
   "metadata": {},
   "source": [
    "# Classifying images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f51aec",
   "metadata": {},
   "source": [
    "In this excercise, we're going to classify images. You'll need to:\n",
    "1. Read images from S3\n",
    "2. Preprocess a dataset.\n",
    "3. Implement a custom `Predictor`.\n",
    "4. Use a pre-trained model to generate predictions.\n",
    "\n",
    "Make sure to reference [the latest version of the AIR documentation](https://docs.ray.io/en/master/ray-air/getting-started.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ae2352",
   "metadata": {},
   "source": [
    "### Task 1: Read images from S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c437e75",
   "metadata": {},
   "source": [
    "First, let's load our image data. We're going to be working with a subset of ImageNet that contains one image of each class. \n",
    "\n",
    "Read the images at `s3://air-example-data-2/imagenet-sample-images/` into a [Ray Dataset](https://docs.ray.io/en/master/data/api/dataset.html). Your dataset should contains 1000 rows, and its representation should look like `Dataset(num_blocks=..., num_rows=1000, schema={image: ..., ...})`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f95e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data import Dataset\n",
    "\n",
    "dataset: Dataset = ...\n",
    "\n",
    "assert dataset.count() == 1000\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.data import Dataset\n",
    "from ray.data.datasource import ImageFolderDatasource\n",
    "\n",
    "dataset: Dataset = ray.data.read_datasource(ImageFolderDatasource(), root=\"s3://air-example-data-2/imagenet-sample-images\", size=(224, 224))\n",
    "\n",
    "assert dataset.count() == 1000\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd592fe",
   "metadata": {},
   "source": [
    "### Task 2: Preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e429f0",
   "metadata": {},
   "source": [
    "Our pretrained model expects inputs to be normalized. If we don't normalize the images, our model won't perform well.\n",
    "\n",
    "Apply `transform` to every image in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])    \n",
    "])\n",
    "\n",
    "transformed_dataset: Dataset = ...\n",
    "\n",
    "assert all(record[\"image\"].shape[0] == 3 for record in transformed_dataset.take_all())\n",
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import BatchMapper\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])    \n",
    "])\n",
    "\n",
    "def preprocess(df):\n",
    "    df.loc[:, \"image\"] = [transform(image) for image in df[\"image\"]]\n",
    "    return df\n",
    "\n",
    "preprocessor = BatchMapper(preprocess)\n",
    "transformed_dataset: Dataset = preprocessor.fit_transform(dataset)\n",
    "\n",
    "assert all(record[\"image\"].shape[0] == 3 for record in transformed_dataset.take_all())\n",
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303125c8",
   "metadata": {},
   "source": [
    "### Task 3: Extend `TorchPredictor`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847680b9",
   "metadata": {},
   "source": [
    "`resnet101` returns confidence scores rather than labels. In the code snippet below, the model returns 1000 logits for each input image. These logits represent the model's confidence that an image is a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0671180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bveeramani/GitHub/ray/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/bveeramani/GitHub/ray/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.train.torch import TorchPredictor\n",
    "from torchvision.models import resnet101\n",
    "\n",
    "model = resnet101(pretrained=True)\n",
    "predictor = TorchPredictor(model)\n",
    "\n",
    "batch = next(transformed_dataset.iter_batches(batch_size=4))[\"image\"].to_numpy()\n",
    "outputs = predictor.predict(batch)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e3d26",
   "metadata": {},
   "source": [
    "Logits aren't relevant to this excercise. So, let's extend the built-in `TorchPredictor` class to return labels instead.\n",
    "\n",
    "Implement `CustomTorchPredictor.call_model`. Your implementation should return a tensor containing the predicted label for each in image in the batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84807adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomTorchPredictor(TorchPredictor):\n",
    "\n",
    "    def call_model(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "predictor = CustomTorchPredictor(model)\n",
    "predictions = predictor.predict(batch)\n",
    "\n",
    "assert predictions.shape == (4,)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomTorchPredictor(TorchPredictor):\n",
    "\n",
    "    def call_model(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        outputs = super().call_model(tensor)\n",
    "        return torch.argmax(outputs, axis=1)\n",
    "\n",
    "\n",
    "predictor = CustomTorchPredictor(model)\n",
    "predictions = predictor.predict(batch)\n",
    "\n",
    "assert predictions.shape == (4,)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f875c5c",
   "metadata": {},
   "source": [
    "**HINT**: Use `torch.argmax` to get predicted labels from model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "outputs = model(torch.zeros(4, 3, 256, 256))\n",
    "assert outputs.shape == (4, 1000)\n",
    "predictions = torch.argmax(outputs, dim=1)\n",
    "assert predictions.shape == (4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d06574",
   "metadata": {},
   "source": [
    "### Task 4: Make predictions for the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8036f39",
   "metadata": {},
   "source": [
    "Now that we've preprocessed our dataset and implemented a custom predictor, we can finally classify the images.\n",
    "\n",
    "Classify all of the images in the dataset, and assign `predictions` to a dataset that describes the predicted labels. The dataset representation should like  looks like `Dataset(num_blocks=..., num_rows=1000, schema={predictions: int64})`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950df26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions: Dataset = ...\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "\n",
    "checkpoint = TorchCheckpoint.from_model(model)\n",
    "batch_predictor = BatchPredictor(checkpoint, CustomTorchPredictor)\n",
    "predictions: Dataset = batch_predictor.predict(transformed_dataset, feature_columns=[\"image\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457d52a",
   "metadata": {},
   "source": [
    "If you did everything correctly, your model should classify 87.6% of the images correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(outputs: Dataset) -> float:\n",
    "    assert outputs.count() == 1000\n",
    "    predicted_labels = [record[\"predictions\"] for record in predictions.take_all()]\n",
    "    return sum(label == expected_label for expected_label, label in enumerate(predicted_labels)) / 1000\n",
    "\n",
    "\n",
    "assert score(predictions) == 0.876"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a658351b4133f922c5967ed6133cfc05c9f16c53a5161e5843ace3f528fccaf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
